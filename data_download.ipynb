{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-15 16:33:58,436 - INFO - Discovering subpackages in _NamespacePath(['c:\\\\Python310\\\\lib\\\\site-packages\\\\pinecone_plugins'])\n",
      "2024-08-15 16:33:58,438 - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2024-08-15 16:33:58,439 - INFO - Installing plugin inference into Pinecone\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6883b0e0cd304baabfb6f7e6523c6e00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-15 16:33:58,917 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:33:59,061 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:33:59,210 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:33:59,350 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:33:59,497 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:33:59,618 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:33:59,816 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:33:59,984 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:00,129 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:00,236 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:00,394 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:00,595 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:00,716 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:00,867 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:01,059 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:01,201 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:01,314 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:01,433 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:01,544 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:01,661 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:01,780 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:01,926 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:02,074 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:02,226 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:02,369 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:02,537 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:02,724 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:02,920 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:03,077 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:03,184 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:03,334 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:03,476 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:03,628 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:03,812 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:03,927 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:04,044 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:04,202 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:04,392 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:04,550 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:04,662 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:04,803 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:05,012 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:05,129 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:05,239 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:05,386 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:05,540 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:05,699 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:05,834 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:06,017 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:06,166 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:06,329 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:06,463 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:06,600 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:06,714 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:06,873 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:07,065 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:07,247 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:07,396 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:07,522 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:07,659 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-08-15 16:34:08,581 - INFO - Data upload complete!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone\n",
    "from tqdm.auto import tqdm\n",
    "from openai import OpenAI\n",
    "import logging\n",
    "import time\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv('.env.local')\n",
    "\n",
    "# Initialize Pinecone\n",
    "pc = Pinecone(api_key=os.getenv('PINECONE_API_KEY'))\n",
    "\n",
    "# Connect to the index\n",
    "index_name = os.getenv('PINECONE_INDEX_NAME')\n",
    "\n",
    "# Check if the index exists, if not create it\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,  # OpenAI's text-embedding-ada-002 uses 1536 dimensions\n",
    "        metric='cosine'\n",
    "    )\n",
    "    logging.info(f\"Created new index: {index_name}\")\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# OpenAI client initialization\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "    try:\n",
    "        text = text.replace(\"\\n\", \" \")\n",
    "        response = client.embeddings.create(input=[text], model=model)\n",
    "        return response.data[0].embedding\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred while getting embedding: {e}\")\n",
    "        if \"Rate limit\" in str(e):\n",
    "            logging.warning(\"Rate limit exceeded. Waiting for 60 seconds before retrying.\")\n",
    "            time.sleep(60)\n",
    "            return get_embedding(text, model)\n",
    "        raise\n",
    "\n",
    "# Load and process the JSON data\n",
    "try:\n",
    "    with open('data/english-dev.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    logging.error(\"The data file 'data/english-dev.json' was not found.\")\n",
    "    sys.exit(1)\n",
    "except json.JSONDecodeError:\n",
    "    logging.error(\"Error decoding the JSON file. Please check if it's valid JSON.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Prepare the data for upsert\n",
    "vectors_to_upsert = []\n",
    "for i, item in enumerate(tqdm(data)):\n",
    "    # Combine all text fields into a single string\n",
    "    text = item['description'] + ' ' + ' '.join(item['utterances'])\n",
    "    \n",
    "    try:\n",
    "        # Get the embedding using OpenAI API\n",
    "        vector = get_embedding(text)\n",
    "        \n",
    "        # Prepare the vector for upsert\n",
    "        vectors_to_upsert.append((str(i), vector, {\"text\": text}))\n",
    "\n",
    "        # Upsert in batches of 100\n",
    "        if len(vectors_to_upsert) == 100:\n",
    "            index.upsert(vectors=vectors_to_upsert)\n",
    "            vectors_to_upsert = []\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing item {i}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Upsert any remaining vectors\n",
    "if vectors_to_upsert:\n",
    "    try:\n",
    "        index.upsert(vectors=vectors_to_upsert)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error upserting final batch: {e}\")\n",
    "\n",
    "logging.info(\"Data upload complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# Upload https://huggingface.co/datasets/ruslanmv/ai-medical-chatbot to pineceone \n",
    "#####################################\n",
    "\n",
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv('.env.local')\n",
    "\n",
    "# Initialize Pinecone\n",
    "api_key = os.getenv('PINECONE_API_KEY')\n",
    "if not api_key:\n",
    "    raise ValueError(\"PINECONE_API_KEY not found in environment variables\")\n",
    "\n",
    "pc = Pinecone(api_key=api_key)\n",
    "\n",
    "# Connect to the index\n",
    "index_name = os.getenv('PINECONE_INDEX_NAME')\n",
    "if not index_name:\n",
    "    raise ValueError(\"PINECONE_INDEX_NAME not found in environment variables\")\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# Function to safely load dataset\n",
    "def safe_load_dataset(dataset_name, split=\"train\"):\n",
    "    try:\n",
    "        return load_dataset(dataset_name, split=split)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        print(\"Attempting to load dataset in streaming mode...\")\n",
    "        return load_dataset(dataset_name, split=split, streaming=True)\n",
    "\n",
    "# Load the dataset from Hugging Face\n",
    "print(\"Loading dataset from Hugging Face...\")\n",
    "dataset = safe_load_dataset(\"ruslanmv/ai-medical-chatbot\")\n",
    "print(\"Dataset loaded successfully.\")\n",
    "\n",
    "# Initialize the SentenceTransformer model for embeddings\n",
    "print(\"Initializing SentenceTransformer model...\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Function to create embeddings\n",
    "def create_embedding(text):\n",
    "    return model.encode(text).tolist()\n",
    "\n",
    "# Prepare and upsert data\n",
    "batch_size = 100\n",
    "vectors_to_upsert = []\n",
    "total_vectors = 0\n",
    "start_time = time.time()\n",
    "\n",
    "print(f\"Starting data upload in batches of {batch_size}...\")\n",
    "for i, item in enumerate(tqdm(dataset, desc=\"Processing items\")):\n",
    "    try:\n",
    "        # Combine all text fields into a single string\n",
    "        text = f\"{item['Description']} {item['Patient']} {item['Doctor']}\"\n",
    "        \n",
    "        # Create embedding\n",
    "        vector = create_embedding(text)\n",
    "        \n",
    "        # Prepare the vector for upsert\n",
    "        vectors_to_upsert.append((str(i), vector, {\"text\": text}))\n",
    "        \n",
    "        # Upsert in batches\n",
    "        if len(vectors_to_upsert) == batch_size:\n",
    "            index.upsert(vectors=vectors_to_upsert)\n",
    "            total_vectors += len(vectors_to_upsert)\n",
    "            vectors_to_upsert = []\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing item {i}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Upsert any remaining vectors\n",
    "if vectors_to_upsert:\n",
    "    index.upsert(vectors=vectors_to_upsert)\n",
    "    total_vectors += len(vectors_to_upsert)\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(f\"Data upload complete!\")\n",
    "print(f\"Total vectors uploaded: {total_vectors}\")\n",
    "print(f\"Total time taken: {total_time:.2f} seconds\")\n",
    "print(f\"Average upload rate: {total_vectors / total_time:.2f} vectors/second\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'if' statement on line 80 (103639978.py, line 83)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[30], line 83\u001b[1;36m\u001b[0m\n\u001b[1;33m    except Exception as e:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after 'if' statement on line 80\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone\n",
    "from tqdm.auto import tqdm\n",
    "from openai import OpenAI\n",
    "import logging\n",
    "import time\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv('.env.local')\n",
    "\n",
    "# Initialize Pinecone\n",
    "pc = Pinecone(api_key=os.getenv('PINECONE_API_KEY'))\n",
    "\n",
    "# Connect to the secondary index\n",
    "index_name = os.getenv('PINECONE_INDEX_SECONDARY')\n",
    "\n",
    "# Check if the index exists, if not create it\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,  # OpenAI's text-embedding-ada-002 uses 1536 dimensions\n",
    "        metric='cosine'\n",
    "    )\n",
    "    logging.info(f\"Created new index: {index_name}\")\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# OpenAI client initialization\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "    try:\n",
    "        text = text.replace(\"\\n\", \" \")\n",
    "        response = client.embeddings.create(input=[text], model=model)\n",
    "        return response.data[0].embedding\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred while getting embedding: {e}\")\n",
    "        if \"Rate limit\" in str(e):\n",
    "            logging.warning(\"Rate limit exceeded. Waiting for 60 seconds before retrying.\")\n",
    "            time.sleep(60)\n",
    "            return get_embedding(text, model)\n",
    "        raise\n",
    "\n",
    "# Load the dataset\n",
    "try:\n",
    "    dataset = load_dataset(\"ruslanmv/ai-medical-chatbot\", split=\"train\", streaming=True)\n",
    "    logging.info(\"Dataset loaded successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading dataset: {e}\")\n",
    "    raise\n",
    "\n",
    "# Prepare the data for upsert\n",
    "vectors_to_upsert = []\n",
    "for i, item in enumerate(tqdm(dataset)):\n",
    "    # Combine all text fields into a single string\n",
    "    text = f\"Description: {item['Description']} Patient: {item['Patient']} Doctor: {item['Doctor']}\"\n",
    "    \n",
    "    try:\n",
    "        # Get the embedding using OpenAI API\n",
    "        vector = get_embedding(text)\n",
    "        \n",
    "        # Prepare the vector for upsert\n",
    "        vectors_to_upsert.append((str(i), vector, {\n",
    "            \"description\": item['Description'],\n",
    "            \"patient\": item['Patient'],\n",
    "            \"doctor\": item['Doctor']\n",
    "        }))\n",
    "\n",
    "        # Upsert in batches of 100\n",
    "        if len(vectors_to_upsert) == 100:\n",
    "            index.upsert(vectors=vectors_to_upsert)\n",
    "            vectors_to_upsert = []\n",
    "\n",
    "        # Optional: Break after processing a certain number of items (e.g., 1000) for testing\n",
    "        if i >= 1000:\n",
    "            break\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing item {i}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Upsert any remaining vectors\n",
    "if vectors_to_upsert:\n",
    "    try:\n",
    "        index.upsert(vectors=vectors_to_upsert)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error upserting final batch: {e}\")\n",
    "\n",
    "logging.info(\"Data upload complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
